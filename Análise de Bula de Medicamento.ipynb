{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309b9bbd",
   "metadata": {},
   "source": [
    "# Desafio 1\n",
    "\n",
    "## Análise de uma Bula de Medicamento\n",
    "\n",
    "**Aluna:** Bianca da Silva Rodrigues\n",
    "\n",
    "**Professor:** Cristiano da Silveira Colombo\n",
    "\n",
    "**Disciplina:** Tópicos Avançados em Bancos de Dados - Mineração de Textos\n",
    "\n",
    "\n",
    "### Instruções \n",
    "\n",
    "1) Faça o download de uma bula de medicamento em PDF (versão paciente) no site Bulário Eletrônico.\n",
    "\n",
    "2) Converta a bula em PDF para o formato TXT (texto puro).\n",
    "\n",
    "3) Efetue o pré-processamento do arquivo no formato TXT de modo a garantir a preparação e limpeza do mesmo, como por exemplo, a retirada de caracteres especiais, espaços em branco e quebras de linha excedentes.\n",
    "\n",
    "4) Identifique e apresente as 20 palavras mais frequentes no texto da bula selecionada por você (não esqueça de retirar as stopwords).\n",
    "\n",
    "5) Gere um arquivo onde sejam apresentadas as 20 palavras mais frequentes e suas respectivas classes gramaticais. Por exemplo: médico (substantivo), ingerir (verbo), etc...\n",
    "\n",
    "6) [Desafio extra \"super power\"] Gere um arquivo onde sejam apresentadas 20 palavras e seus respectivos \"conceitos\". Por exemplo: médico (pessoa), enxaqueca (sintoma), câncer (doença), dipirona (medicamento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 nltk spacy\n",
    "import PyPDF2\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "!python -m spacy download pt_core_news_sm\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "caminho_pdf = 'dipirona.pdf'\n",
    "\n",
    "def extrair_texto_de_pdf(caminho_pdf):\n",
    "    texto = ''\n",
    "    with open(caminho_pdf, 'rb') as arquivo_pdf:\n",
    "        pdf = PyPDF2.PdfReader(arquivo_pdf)\n",
    "        num_paginas = len(pdf.pages)\n",
    "        for pagina in range(num_paginas):\n",
    "            texto += pdf.pages[pagina].extract_text()\n",
    "    return texto\n",
    "\n",
    "texto_bula = extrair_texto_de_pdf(caminho_pdf)\n",
    "\n",
    "# Verifica o conteúdo do texto\n",
    "print(texto_bula)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfebdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina uma função para pré-processamento\n",
    "def preprocessamento(texto):\n",
    "    # Converte o texto para minúsculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Mantém palavras com acentos e remove apenas números e sinais\n",
    "    texto = re.sub(r'[^a-zA-ZáÁéÉíÍóÓúÚâÂêÊôÔãÃõÕçÇ]', ' ', texto)\n",
    "\n",
    "    \n",
    "    # Tokenização em palavras\n",
    "    palavras = word_tokenize(texto)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    palavras_filtradas = [palavra for palavra in palavras if palavra not in stop_words]\n",
    "    \n",
    "    # Junte as palavras em um único texto\n",
    "    texto_limpo = ' '.join(palavras_filtradas)\n",
    "    \n",
    "    return texto_limpo\n",
    "\n",
    "texto_preprocessado = preprocessamento(texto_bula)\n",
    "\n",
    "# Verifica o texto após o pré-processamento\n",
    "print(texto_preprocessado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b59990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização do texto pré-processado novamente\n",
    "palavras = word_tokenize(texto_preprocessado)\n",
    "\n",
    "# Contagem das palavras\n",
    "contagem_palavras = Counter(palavras)\n",
    "\n",
    "# 20 palavras mais frequentes\n",
    "palavras_mais_frequentes = contagem_palavras.most_common(20)\n",
    "\n",
    "# Imprima as 20 palavras mais frequentes\n",
    "for palavra, frequencia in palavras_mais_frequentes:\n",
    "    print(f'{palavra}: {frequencia}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3534075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'palavras_frequentes_com_classes.txt' gerado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Carregue o modelo de língua em português\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "# Processamento do texto com spaCy\n",
    "doc = nlp(texto_preprocessado)\n",
    "\n",
    "# Dicionário para mapear classes gramaticais para rótulos mais legíveis\n",
    "rotulos_classes_gramaticais = {\n",
    "    'NOUN': 'substantivo',\n",
    "    'VERB': 'verbo',\n",
    "    'ADJ': 'adjetivo',\n",
    "    'ADV': 'advérbio',\n",
    "    'ADP': 'preposição',\n",
    "    'PRON': 'pronome',\n",
    "    'DET': 'determinante',\n",
    "    'CONJ': 'conjunção',\n",
    "    'NUM': 'número',\n",
    "    'PUNCT': 'pontuação'\n",
    "}\n",
    "\n",
    "# Encontre e imprima as 20 palavras mais frequentes com suas classes gramaticais\n",
    "palavras_com_classes = []\n",
    "for palavra, frequencia in palavras_mais_frequentes:\n",
    "    token = nlp(palavra)[0]\n",
    "    classe_gramatical = token.pos_\n",
    "    classe_gramatical_legivel = rotulos_classes_gramaticais.get(classe_gramatical, 'desconhecida')\n",
    "    palavras_com_classes.append((palavra, classe_gramatical_legivel))\n",
    "\n",
    "# Salve as palavras mais frequentes e suas classes em um arquivo\n",
    "with open('palavras_frequentes_com_classes.txt', 'w') as arquivo_saida:\n",
    "    for palavra, classe in palavras_com_classes:\n",
    "        arquivo_saida.write(f'{palavra} ({classe})\\n')\n",
    "\n",
    "print(\"Arquivo 'palavras_frequentes_com_classes.txt' gerado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8fc59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'palavras_conceitos.txt' gerado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Dicionário manual de exemplo que associa palavras a conceitos\n",
    "dicionario_conceitos = {\n",
    "    'médico': 'pessoa',\n",
    "    'enxaqueca': 'sintoma',\n",
    "    'dipirona': 'medicamento'\n",
    "    # Adicione mais palavras e conceitos conforme necessário\n",
    "}\n",
    "\n",
    "# Encontre as 20 palavras mais frequentes (já fizemos isso no Passo 4)\n",
    "palavras_mais_frequentes = [palavra for palavra, _ in palavras_mais_frequentes]\n",
    "\n",
    "# Vincule palavras a conceitos com base no dicionário\n",
    "conceitos_associados = []\n",
    "for palavra in palavras_mais_frequentes:\n",
    "    conceito = dicionario_conceitos.get(palavra, 'desconhecido')\n",
    "    conceitos_associados.append((palavra, conceito))\n",
    "\n",
    "# Salve as palavras e seus conceitos em um arquivo\n",
    "with open('palavras_conceitos.txt', 'w') as arquivo_saida:\n",
    "    for palavra, conceito in conceitos_associados:\n",
    "        arquivo_saida.write(f'{palavra}: {conceito}\\n')\n",
    "\n",
    "print(\"Arquivo 'palavras_conceitos.txt' gerado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab0e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
